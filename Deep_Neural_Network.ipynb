{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rikharigaurav/FSDL-text-recognizer/blob/main/Deep_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blRRYw5o1cyz"
      },
      "source": [
        "Pytorch is library used to simplify deep learning\n",
        "\n",
        "it provides designed modules and classes to create nueral network, optimization, Datasets and Dataloaders\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vGZTpEMFzTU"
      },
      "source": [
        "# what is torch.nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHucuMRZ1uX-"
      },
      "source": [
        "\n",
        "to answer this question we will use MNIST datset .\n",
        "this datset consists of black and white images of hand-written digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PJ4EzG4Y2qCR"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "\n",
        "def download_mnist(path):\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    if not (path / filename).exists():\n",
        "        content = requests.get(url + filename).content\n",
        "        (path / filename).open(\"wb\").write(content)\n",
        "\n",
        "    return path / filename\n",
        "\n",
        "\n",
        "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
        "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
        "path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "datafile = download_mnist(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qRn28odI3QK1"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "def read_mnist(path):\n",
        "  with gzip.open(path, \"rb\") as f:\n",
        "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "  return x_train, y_train, x_valid, y_valid\n",
        "\n",
        "x_train, y_trian, x_valid, y_valid = read_mnist(datafile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzm8fno93sQa"
      },
      "source": [
        "Since each image is 28 X 28. so we need to flatten it so the number of rows = 784(28X28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "B--mygmR4C6Q",
        "outputId": "327dd984-c8e4-4d53-c7f5-1706e41f4df2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.imshow(x_train[0].reshape((28, 28)), cmap = \"gray\")\n",
        "\n",
        "plt.show()\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9MAWf074f8A"
      },
      "source": [
        "Neural net from scratch (without torch.nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYIFiJwi5kX7"
      },
      "source": [
        "**STEP 1:** we will initialize the weights and biases. Here we are using the Xavier initialization\n",
        "\n",
        "**Xavier initialization:** multipying with (1/sqrt(n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FeLIsrz35LX6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YYN8hCvVHVp"
      },
      "source": [
        "**Step 2:** Create an activation function\n",
        "\n",
        "Activation Function is used to prevent linearity in the prediction. otherwise the nodes will act as an linear function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dcwI78wXVIaU"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):\n",
        "  return log_softmax(xb @ weights + bias) # @ helps in matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmxQ_sIoV3bw"
      },
      "source": [
        "Here we are doing FORWARD PASS (forward pass is nothing but just predicting the output).\n",
        "\n",
        "**Note** Right now the prediction won't be better. They will we just random prediction due to random values of weights and bias.\n",
        "\n",
        "\n",
        "\n",
        "but at"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U4KtJGyWfEX",
        "outputId": "5efae6a2-7334-4bce-d8f6-b421b2369c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.8468, -2.2549, -2.5217, -2.4722, -1.8608, -2.4577, -3.0645, -2.7985,\n",
            "        -1.9187, -2.5627], grad_fn=<SelectBackward0>) torch.Size([32, 10])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "xb = x_train[0:batch_size]  # This creates a mini-batch from the x_train\n",
        "preds = model(torch.from_numpy(xb))    # Prediction\n",
        "\n",
        "# torch.from_numpy help to convert numpy array to tensor to support matrix multiplication\n",
        "\n",
        "preds[0], preds.shape\n",
        "print(preds[0], preds.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG4fsT4gYghB"
      },
      "source": [
        "Let's implement -ve log-likelihood to use as the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KrZevHOYYxsO"
      },
      "outputs": [],
      "source": [
        "def nll(input, target):\n",
        "  return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wYc7ipEGHWk"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nwrd3i8GLsu",
        "outputId": "db14041e-65bd-4ad2-ad91-34b4dbd490d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=.:/env/python\n",
            ".:/env/python\n",
            "/content/fsdl-text-recognizer-2022-labs/lab01\n",
            "\u001b[0m\u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mtext_recognizer\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "lab_idx = 1\n",
        "\n",
        "if \"bootstrap\" not in locals() or bootstrap.run:\n",
        "    # path management for Python\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if \".\" not in pythonpath.split(\":\"):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    # change into the lab directory\n",
        "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
        "\n",
        "    # allow \"hot-reloading\" of modules\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    # needed for inline plots in some contexts\n",
        "    %matplotlib inline\n",
        "\n",
        "    bootstrap.run = False  # change to True re-run setup\n",
        "\n",
        "!pwd\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kg1nFaII5Ma"
      },
      "source": [
        "# Getting data and making tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jfmG78IJI9xi"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "\n",
        "def download_mnist(path):\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    if not (path / filename).exists():\n",
        "        content = requests.get(url + filename).content\n",
        "        (path / filename).open(\"wb\").write(content)\n",
        "\n",
        "    return path / filename\n",
        "\n",
        "\n",
        "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
        "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
        "path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "datafile = download_mnist(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TECaHqPfJf6s"
      },
      "source": [
        "The data used above is generally too large to be stored on a disk.\n",
        "\n",
        "so fetching data over a network is a common first step in model training\n",
        "\n",
        "The dataset above is too large which can require more resource to read, write and sending over the network - so the datasets is compressed (.gz extension)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dHbnbib5Kbvs"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "def read_mnist(path):\n",
        "  with gzip.open(path, \"rb\") as f:\n",
        "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "  return x_train, y_train, x_valid, y_valid\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = read_mnist(datafile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYMhAey1LKb8"
      },
      "source": [
        "torch.tensor helps us to convert our array into tensor\n",
        "\n",
        "Tensor: Tensor in ML is just like an n-dimension array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Pl186c7wLoX3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBvUlosOL0GN",
        "outputId": "8d6b7177-22cb-4475-fbf0-06976df56b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([5, 0, 4,  ..., 8, 4, 8])\n"
          ]
        }
      ],
      "source": [
        "print(x_train, y_train, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5wEUaKYL6I0"
      },
      "source": [
        "Accessing the content of Tensor is called \"indexing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXqMTkPzM04i",
        "outputId": "d0397c3b-38f7-46f9-d4c3-7f50cbfe9d4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5),\n",
              " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0117, 0.0703, 0.4922, 0.6836, 0.6484,\n",
              "         0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.3672,\n",
              "         0.6641, 0.9883, 0.9883, 0.8789, 0.9883, 0.7617, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.9297, 0.9883, 0.9883, 0.9883, 0.9883, 0.3633,\n",
              "         0.3203, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8555,\n",
              "         0.9883, 0.9883, 0.7734, 0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.4180, 0.9883, 0.0430, 0.1680,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0039, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.0078,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.7422, 0.2734, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1367,\n",
              "         0.8789, 0.4219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.9883, 0.0977, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1758, 0.9883, 0.5859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3633, 0.9883,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.2500, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.7148,\n",
              "         0.9883, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1523, 0.8945, 0.9883, 0.9766, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0938, 0.8633, 0.9883,\n",
              "         0.9883, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0898, 0.8320, 0.9883, 0.9883, 0.3164, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.8555, 0.9883, 0.9883,\n",
              "         0.3125, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2148, 0.8828, 0.9883, 0.9883, 0.5195, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5312, 0.9883, 0.8281, 0.5156,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "y_train[0], x_train[0, ::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccdiQNUxM6mC",
        "outputId": "4579f993-208a-44a5-c5ba-f249d2cbbd04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# .ndim provide the dimension of the following tensor\n",
        "\n",
        "x_train.ndim, y_train.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QpYVo99NHD6",
        "outputId": "e161e501-49e2-4fe0-80c1-77d658b6cf55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.), tensor(5))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "x_train[0, 0], y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3It1tkzNkOB",
        "outputId": "1e25059c-ffa7-4ab4-db79-965cba9be004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000, 784])\n",
            "torch.Size([50000])\n"
          ]
        }
      ],
      "source": [
        "n, c = x_train.shape\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDO23f8-OKc4"
      },
      "source": [
        "The Tensors inside of the x_train Tensor aren't just any old blocks of numbers: they're images of handwritten digits. The y_train Tensor contains the identities of those digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9sx1OPwjOrus",
        "outputId": "d96147b3-c5f5-41e4-b509-15e224b43b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB3UlEQVR4nO2Uoa+CUBTGr+yZKBaCIxgswqZkA1RGYnMzGJ3BIIVu0eyUzX9E7SSSbqTrdNjAYIBCkHJ34QX2GNP3Luh78X2JsY/fOfdyvgPAv/5alUIHz/ONRiN9ns1m/X7fdd3fljUMA30JY2ya5nQ6fR/HsuxgMAiCIA9FCEVR5DiO4zgsy75GFAQBQphSHqCZjsejIAgv9AghfKbs93tZlj3Py2pMJpOy0MvlgjHGGCdJomnat575fJ4kCca42WyWgjqOk/aiaVqn0/nJlp6jGErT9GKxiKIIIVQ4OtfrFSFkWRbDMCSfoijZDcqyTIbyPG/bNkLINM1slgEA1E8f7HY727bJ0NPpZFkWAECSpFarRYJSFEVRlOd5QRCQoQCASqXybP549sVxDABIkqSQyPO8KIpxHG+32/yxHju93+9hGAIAarUaTdNkaLfbbbfbhbUByIWd/KNUVU1Hyvf9Xq9XAOU4Ls0MAaqq6u12S6Hn87lUs1miDoeDoiiSJKXvGYZRFGU0GmV5gxDW6/VSUF3X8xskCALDMAzD2Gw2+VUAISTk7VHValXX9TAMCVvKdd2yPeY1Ho9Xq1WamTzU9/3lcslx3MvETBzHDYfDDLper0VRfB/3r/f0CYm0m9inIxI4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# re-execute this cell for more samples\n",
        "import random\n",
        "\n",
        "import wandb  # just for some convenience methods that convert tensors to human-friendly datatypes\n",
        "\n",
        "import text_recognizer.metadata.mnist as metadata # metadata module holds metadata separate from data\n",
        "\n",
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx]\n",
        "\n",
        "print(y_train[idx])  # the label of the image\n",
        "wandb.Image(example.reshape(*metadata.DIMS)).image  # the image itself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NuDq7NGPcCN"
      },
      "source": [
        "# Building a DNN using only torch.Tensor methods and Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUBeTVBOTpPK"
      },
      "source": [
        "## Defining the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50a4S-MET8ZS"
      },
      "source": [
        "We'll make the simplest possible neural network: a single layer that performs matrix multiplication, and adds a vector of biases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3zk4hWxTcy6T"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Axf3DMouczSy"
      },
      "outputs": [],
      "source": [
        "def linear(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x @ weights + bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lbrss7OczWV"
      },
      "source": [
        "We need to normalize our model's outputs with a softmax to get our model to output something we can use as a probability distribution -- the probability that the network assigns to each label for the image.\n",
        "\n",
        "For that, we'll need some torch math functions, like torch.sum and torch.exp.\n",
        "\n",
        "We compute the logarithm of that softmax value in part for numerical stability reasons and in part because [it is more natural to work with the logarithms of probabilities.](https://www.youtube.com/watch?v=LBemXHm_Ops&t=1071s)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B4rjKxpJdXr3"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x - torch.log(torch.sum(torch.exp(x), axis=1))[:, None]\n",
        "\n",
        "def model(xb: torch.Tensor) -> torch.Tensor:\n",
        "    return log_softmax(linear(xb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDydxpQ9egHZ",
        "outputId": "7065d158-a035-411b-b9f7-52fb9f50ceb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.7320, -2.0166, -2.4598, -2.9528, -2.5942, -2.0071, -1.9456, -2.2302,\n",
            "        -2.3395, -2.2231], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "bs = 64  # batch size\n",
        "\n",
        "xb = x_train[0:bs]  # a mini-batch of inputs\n",
        "outs = model(xb)  # outputs on that batch\n",
        "\n",
        "print(outs[0], outs.shape)  # outputs on the first element of the batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJVfzdWaTuyr"
      },
      "source": [
        "## Defining the loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQjdHj2aT4_1"
      },
      "source": [
        "Since we have set the weights randomly ofcourse we are going to get wrong prediction\n",
        "\n",
        "We need to compare the output and the target variable to let our model know that how to update the values of weights\n",
        " but the model outputs a probability distribution, and the labels are just numbers.\n",
        "\n",
        "We can take the label that had the highest probability (the index of the largest output for each input, aka the argmax over dimension 1) and treat that as the model's prediction for the digit in the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "An3MpNPRfgGP"
      },
      "outputs": [],
      "source": [
        "def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
        "  preds = torch.argmax(out, dim=1)\n",
        "  return (preds == yb).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAo3oLtSfgvo",
        "outputId": "59d5c8d1-cae6-439b-d4bd-2424e65a2726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1094)\n"
          ]
        }
      ],
      "source": [
        "yb = y_train[0:bs]\n",
        "\n",
        "acc = accuracy(outs, yb)\n",
        "\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRm9WddBfgzU"
      },
      "source": [
        "We can calculate how good our network is doing, so are we ready to use optimization to make it do better?\n",
        "\n",
        "Not yet! To train neural networks, we use gradients (aka derivatives). So all of the functions we use need to be differentiable -- in particular they need to change smoothly so that a small change in input can only cause a small change in output.\n",
        "\n",
        "Our argmax breaks that rule (if the values at index 0 and index N are really close together, a tiny change can change the output by N) so we can't use it.\n",
        "\n",
        "If we try to run our backwards pass to get a gradient, we get a RuntimeError:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySbI4agRV1VF",
        "outputId": "f0e01e2d-f289-4112-8195-b43925082ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "element 0 of tensors does not require grad and does not have a grad_fn\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  acc.backward()\n",
        "except RuntimeError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GY4ufDHEV1XP"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "  return -output[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFyP-gE8V1fT",
        "outputId": "5b83e0e8-fafe-4571-9e46-a1c1db1c4ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3670, grad_fn=<NegBackward0>) tensor(2.3026)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(outs, yb), -torch.log(torch.tensor(1 / 10)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "50OamddYcvdB"
      },
      "outputs": [],
      "source": [
        "loss = loss_func(outs, yb)\n",
        "\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29kAbgq5c221",
        "outputId": "46762bd6-ba2a-40bf-bdbe-b525d117ab6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0228, -0.0321,  0.0185, -0.0146, -0.0575,  0.0769,  0.0310,  0.0432,\n",
              "        -0.0103, -0.0321])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "bias.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXrIy3CuUE-u"
      },
      "source": [
        "## Defining and running the fitting loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZriHsBoUKXl"
      },
      "source": [
        "We now have all the ingredients we need to fit a neural network to data:\n",
        "- data (`x_train`, `y_train`)\n",
        "- a network architecture with parameters (`model`, `weights`, and `bias`)\n",
        "- a `loss_func`tion to optimize (`cross_entropy`) that supports `.backward` computation of gradients\n",
        "\n",
        "We can put them together into a training loop\n",
        "just using normal Python features,\n",
        "like `for` loops, indexing, and function calls:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hnmffzPGdRkt"
      },
      "outputs": [],
      "source": [
        "lr = 0.5 #learning_rate\n",
        "epochs = 2 # how many epochs to train for\n",
        "\n",
        "for epoch in range(epochs):   # iterates over dataset for no. of epochs\n",
        "  for i in range((n-1) // bs + 1):  # iterates over the dataset in batch size\n",
        "    # determines the indexs of batch\n",
        "    start_idx = i * bs\n",
        "    end_idx = start_idx + bs\n",
        "\n",
        "    # Creates batch from the large dataset\n",
        "    xb = x_train[start_idx : end_idx]\n",
        "    yb = y_train[start_idx : end_idx]\n",
        "\n",
        "    # runs the model on mini batch to generate prediction\n",
        "    pred = model(xb)\n",
        "\n",
        "    # calculates the loss between actual target and prediction\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    #calculate the gradients with a backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # updates the parameters\n",
        "    with torch.no_grad():  # we don't want to track gradients through this part!\n",
        "      # SGD learning rule: update with negative gradient scaled by lr\n",
        "      weights -= weights.grad * lr\n",
        "      bias -= bias.grad * lr\n",
        "\n",
        "      '''NOTE: PyTorch doesn't assume you're done with gradients\n",
        "          until you say so -- by explicitly \"deleting\" them,\n",
        "          i.e. setting the gradients to 0\n",
        "      '''\n",
        "      weights.grad.zero_()\n",
        "      bias.grad.zero_()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9ASBK1igzv-"
      },
      "source": [
        "To check the function is working we will confirm if the values of  `loss_func` and `accuracy` has gone down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_rUY4bXG0UV",
        "outputId": "38d976b3-90c5-4260-84c8-3891b5b4188a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0829, grad_fn=<NegBackward0>) tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yeOKVe12G4or"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsTqOvxzOAa1"
      },
      "source": [
        "# Refactoring with core `torch.nn` components\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVlmiQtkHIP4"
      },
      "source": [
        "\n",
        "For the next few sections,\n",
        "we'll progressively refactor this code to\n",
        "make it shorter, cleaner,\n",
        "and more extensible\n",
        "using tools from the sublibraries of PyTorch:\n",
        "`torch.nn`, `torch.optim`, and `torch.utils.data`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeOO7gIcSlwT"
      },
      "source": [
        "## Using torch.nn.functional for stateless computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r4GFpsHS-jk"
      },
      "source": [
        "First, let's drop that `cross_entropy` and `log_softmax`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "H3srC7dDTdoh"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "  return xb @ weights + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1ojKKlLTowi",
        "outputId": "06fbc0bf-c4aa-423e-b688-9bf340768ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0829, grad_fn=<NllLossBackward0>) tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))  # should be unchanged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr1gzYluSynk"
      },
      "source": [
        "## Using torch.nn.Module to define functions whose state is given by torch.nn.Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuYtElKgTr0O"
      },
      "source": [
        "Challenge:- Handling State in Nueral Network. In DNN the tension arises from the desire to treat neural network as functions during inference, where inputs are transformed into outputs, while they are inherently stateful due to the need for parameter optimization during training.\n",
        "\n",
        "We want to use them as a functions\n",
        "\n",
        "PyTorch's solution to this is the `nn.Module` class:\n",
        "a Python class that is callable like a function\n",
        "but tracks state like an object.\n",
        "\n",
        "  `nn.Parameter` is a wrapper around a Tensor that tells PyTorch that it should be considered a parameter of the model and will be optimized during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PU3dh2ANWbyT"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class MNISTLogistic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()    # calls the parent class\n",
        "    self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "    self.bias = nn.Parameter(torch.zeros(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLr5Ro4wX1Yv"
      },
      "source": [
        "We've separated the definition of the `.forward` method\n",
        "from the definition of the class above and\n",
        "attached the method to the class manually below.\n",
        "We only do this to make the construction of the class\n",
        "easier to read and understand in the context this notebook --\n",
        "a neat little trick we'll use a lot in these labs.\n",
        "Normally, we'd just define the `nn.Module` all at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_GcuI3WmkS7",
        "outputId": "7c77600e-5369-4129-8fe0-eb522357eb58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2032,  0.1429,  0.0637, -0.4344,  0.3306,  0.0201, -0.4481, -0.2385,\n",
            "         -0.0136,  0.2526],\n",
            "        [-0.5377,  0.0714,  0.2654,  0.1298,  0.1520,  0.3625, -0.3697, -0.2808,\n",
            "          0.1002,  0.1414],\n",
            "        [-0.4136,  0.6999,  0.5284, -0.2328,  0.2124, -0.0412, -0.0383,  0.0316,\n",
            "          0.2814, -0.2564],\n",
            "        [-0.3209,  0.1674,  0.4784, -0.0374,  0.1948, -0.1753, -0.2911, -0.4135,\n",
            "          0.3794,  0.2618]], grad_fn=<SliceBackward0>)\n",
            "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 4.0298e-03,  9.7214e-03,  7.2590e-03,  4.5825e-03,  6.5048e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-4.1831e-02,  6.6610e-03,  5.2062e-02,  3.3785e-02, -1.3259e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-3.3538e-02,  2.2629e-02, -3.9733e-02,  1.0764e-02, -4.1083e-02],\n",
            "        [ 1.7107e-02,  3.0956e-02,  2.0109e-02,  1.4131e-02, -5.0546e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-8.4997e-02,  3.7417e-02,  4.8924e-02,  3.2004e-02, -2.2053e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-1.0150e-01,  2.9656e-02,  7.8388e-03,  1.7544e-02, -1.4898e-02],\n",
            "        [-7.0300e-02,  7.5778e-02,  5.9495e-02,  3.9174e-02, -1.1254e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.0291e-02,  3.2717e-02,  2.6328e-02,  1.6993e-02, -4.4886e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-5.7311e-02,  6.9638e-03,  7.8705e-03,  4.0433e-03,  6.8429e-03],\n",
            "        [ 1.5709e-02,  2.9175e-02, -5.6698e-02,  1.6691e-02, -4.1372e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.1946e-02,  6.0372e-02, -1.3977e-02,  3.3522e-02, -7.5298e-02],\n",
            "        [ 5.3193e-03,  7.2786e-03, -5.6587e-02,  4.4272e-03,  6.8600e-03],\n",
            "        [-2.8323e-02,  4.3233e-03,  4.4486e-03,  2.5478e-03,  4.0908e-03],\n",
            "        [-2.6519e-02, -4.9084e-03, -4.6231e-02,  3.7476e-02,  4.1554e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-3.2082e-02,  7.2389e-03, -3.7490e-02,  4.0295e-02, -8.3714e-02],\n",
            "        [-5.6058e-02,  9.8732e-03,  8.1116e-03,  6.3869e-03,  8.2226e-03],\n",
            "        [-1.3458e-03,  1.8227e-04,  1.5420e-04,  1.2735e-04,  1.6199e-04],\n",
            "        [-6.1691e-02,  5.7200e-02, -2.6445e-03,  2.7444e-02, -1.0945e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-9.8477e-02,  5.2613e-02, -5.5770e-03,  3.8956e-02, -6.4362e-02],\n",
            "        [-5.6128e-02,  9.7966e-03,  7.9938e-03,  6.3368e-03,  8.1426e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-1.2218e-01,  4.1946e-02,  8.4245e-02,  5.7831e-02, -1.0063e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.3132e-02,  2.0602e-02,  1.8132e-02,  1.0144e-02, -4.5174e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 5.0764e-04,  9.3250e-04,  1.1566e-03,  7.4982e-04,  7.9947e-04],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
          ]
        }
      ],
      "source": [
        "def forward(self, xb: torch.Tensor) -> torch.Tensor:\n",
        "  return xb @ self.weights + self.bias\n",
        "\n",
        "MNISTLogistic.forward = forward\n",
        "\n",
        "model = MNISTLogistic()\n",
        "print(model(xb)[:4])\n",
        "loss = loss_func(model(xb), yb)\n",
        "loss.backward()\n",
        "print(model.weights.grad[::17, ::2])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But how do we apply our updates?\n",
        "Do we need to access `model.weights.grad` and `model.weights`,\n",
        "like we did in our first implementation?\n",
        "\n",
        "Luckily, we don't!\n",
        "We can iterate over all of our model's `torch.nn.Parameters`\n",
        "via the `.parameters` method:"
      ],
      "metadata": {
        "id": "VI0U7qVJp1dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRQXBOCqdNkQ",
        "outputId": "115c2206-f10a-479c-867f-94086092d842"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0287,  0.0234,  0.0309,  ...,  0.0204,  0.0585,  0.0417],\n",
            "        [-0.0336,  0.0014,  0.0083,  ...,  0.0037, -0.0010, -0.0162],\n",
            "        [ 0.0406, -0.0121, -0.0336,  ...,  0.0083, -0.0285, -0.0703],\n",
            "        ...,\n",
            "        [ 0.0635,  0.0409,  0.0047,  ...,  0.0086, -0.0462,  0.0088],\n",
            "        [ 0.0284,  0.0115, -0.0262,  ..., -0.0189, -0.0226,  0.0544],\n",
            "        [ 0.0431, -0.0235,  0.0300,  ..., -0.0214, -0.0017,  0.0351]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That means we no longer need to assume we know the names\n",
        "of the model's parameters when we do our update --\n",
        "we can reuse the same loop with different models.\n",
        "\n",
        "Let's wrap up into single function to `fit` our model"
      ],
      "metadata": {
        "id": "i7mfrEQbdPUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n - 1) // bs + 1):\n",
        "      start_idx = i * bs\n",
        "      end_idx = start_idx + bs\n",
        "      xb = x_train[start_idx : end_idx]\n",
        "      yb = y_train[start_idx : end_idx]\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * lr\n",
        "        model.zero_grad()\n",
        "\n",
        "fit()"
      ],
      "metadata": {
        "id": "ShICn87-7POT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6CcfK3H8Zvu",
        "outputId": "c593ea85-d181-436d-806d-9f158440612b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Refactoring intermediate `torch.nn` components: network layers, optimizers, and data handling"
      ],
      "metadata": {
        "id": "djYhdwz38ai3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `torch.nn.Linear` for the model definition"
      ],
      "metadata": {
        "id": "Im6rxI-l8al3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These `nn.Module`s are reusable --\n",
        "say, if we want to make a network with multiple layers of the same type --\n",
        "and there are lots of them already defined:"
      ],
      "metadata": {
        "id": "e11obvEP8-Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "print(\"torch.nn.Modules\", *textwrap.wrap(\", \".join(torch.nn.modules.__all__)), sep=\"\\n\\t\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hADq4QX-4ge",
        "outputId": "f0cdaa34-a572-4791-f7e0-5d4dd00300d1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.nn.Modules\n",
            "\tModule, Identity, Linear, Conv1d, Conv2d, Conv3d, ConvTranspose1d,\n",
            "\tConvTranspose2d, ConvTranspose3d, Threshold, ReLU, Hardtanh, ReLU6,\n",
            "\tSigmoid, Tanh, Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GLU,\n",
            "\tGELU, Hardshrink, LeakyReLU, LogSigmoid, Softplus, Softshrink,\n",
            "\tMultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU,\n",
            "\tL1Loss, NLLLoss, KLDivLoss, MSELoss, BCELoss, BCEWithLogitsLoss,\n",
            "\tNLLLoss2d, PoissonNLLLoss, CosineEmbeddingLoss, CTCLoss,\n",
            "\tHingeEmbeddingLoss, MarginRankingLoss, MultiLabelMarginLoss,\n",
            "\tMultiLabelSoftMarginLoss, MultiMarginLoss, SmoothL1Loss,\n",
            "\tGaussianNLLLoss, HuberLoss, SoftMarginLoss, CrossEntropyLoss,\n",
            "\tContainer, Sequential, ModuleList, ModuleDict, ParameterList,\n",
            "\tParameterDict, AvgPool1d, AvgPool2d, AvgPool3d, MaxPool1d, MaxPool2d,\n",
            "\tMaxPool3d, MaxUnpool1d, MaxUnpool2d, MaxUnpool3d, FractionalMaxPool2d,\n",
            "\tFractionalMaxPool3d, LPPool1d, LPPool2d, LocalResponseNorm,\n",
            "\tBatchNorm1d, BatchNorm2d, BatchNorm3d, InstanceNorm1d, InstanceNorm2d,\n",
            "\tInstanceNorm3d, LayerNorm, GroupNorm, SyncBatchNorm, Dropout,\n",
            "\tDropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout,\n",
            "\tReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad2d,\n",
            "\tReplicationPad1d, ReplicationPad3d, CrossMapLRN2d, Embedding,\n",
            "\tEmbeddingBag, RNNBase, RNN, LSTM, GRU, RNNCellBase, RNNCell, LSTMCell,\n",
            "\tGRUCell, PixelShuffle, PixelUnshuffle, Upsample, UpsamplingNearest2d,\n",
            "\tUpsamplingBilinear2d, PairwiseDistance, AdaptiveMaxPool1d,\n",
            "\tAdaptiveMaxPool2d, AdaptiveMaxPool3d, AdaptiveAvgPool1d,\n",
            "\tAdaptiveAvgPool2d, AdaptiveAvgPool3d, TripletMarginLoss, ZeroPad1d,\n",
            "\tZeroPad2d, ZeroPad3d, ConstantPad1d, ConstantPad2d, ConstantPad3d,\n",
            "\tBilinear, CosineSimilarity, Unfold, Fold, AdaptiveLogSoftmaxWithLoss,\n",
            "\tTransformerEncoder, TransformerDecoder, TransformerEncoderLayer,\n",
            "\tTransformerDecoderLayer, Transformer, LazyLinear, LazyConv1d,\n",
            "\tLazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d,\n",
            "\tLazyConvTranspose3d, LazyBatchNorm1d, LazyBatchNorm2d,\n",
            "\tLazyBatchNorm3d, LazyInstanceNorm1d, LazyInstanceNorm2d,\n",
            "\tLazyInstanceNorm3d, Flatten, Unflatten, Hardsigmoid, Hardswish, SiLU,\n",
            "\tMish, TripletMarginWithDistanceLoss, ChannelShuffle, CircularPad1d,\n",
            "\tCircularPad2d, CircularPad3d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTLogistic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lin = nn.Linear(784, 10)  #pytorch finds the nn.Parameter inside this nn.Module\n",
        "\n",
        "  def forward(self, xb):\n",
        "    return self.lin(xb)   # this function call nn.Linear.forward here"
      ],
      "metadata": {
        "id": "tdbw24pk_Lk_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-JtuUL7_LoU",
        "outputId": "c4d53854-5082-4997-8148-b0999f94f371"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3596, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the `nn.Linear` module is a \"child\"\n",
        "of the `model`,\n",
        "and we don't see the matrix of weights and the bias vector:"
      ],
      "metadata": {
        "id": "Zsrz4T4AAGg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.children()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a53ZuyUXAGk_",
        "outputId": "1e17c6f5-9d87-4452-869d-cdbef1a0b1ec"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=784, out_features=10, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYDdwhRhAGqQ",
        "outputId": "b1703dcc-bad9-45be-8809-27ed52136c2c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0182, -0.0192,  0.0002,  ...,  0.0018, -0.0249, -0.0075],\n",
            "        [-0.0106,  0.0301, -0.0168,  ...,  0.0044, -0.0166, -0.0255],\n",
            "        [-0.0127,  0.0192,  0.0121,  ...,  0.0295, -0.0019,  0.0123],\n",
            "        ...,\n",
            "        [ 0.0246,  0.0276, -0.0302,  ...,  0.0313,  0.0033,  0.0006],\n",
            "        [-0.0179, -0.0020, -0.0273,  ...,  0.0322,  0.0250,  0.0338],\n",
            "        [-0.0148,  0.0041, -0.0293,  ...,  0.0084,  0.0195, -0.0163]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0058, -0.0321, -0.0115,  0.0292, -0.0355,  0.0307,  0.0112, -0.0343,\n",
            "         0.0241, -0.0292], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Applying gradient with torch.optim.Optimizer"
      ],
      "metadata": {
        "id": "T_oBBF7aA1dV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So why are we doing that by hand?\n",
        "Now that our model is a `torch.nn.Module` using `torch.nn.Parameters`,\n",
        "we don't have to --\n",
        "we just need to point a `torch.optim.Optimizer`\n",
        "at the parameters of our model.\n",
        "\n",
        "While we're at it, we can also use a more sophisticated optimizer --\n",
        "`Adam` is a common first choice."
      ],
      "metadata": {
        "id": "CTKN7CLuBBtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "def config_optimizer(model: nn.Module) -> optim.Optimizer:\n",
        "  return optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "F3RjtugsBhyz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "opt = config_optimizer(model)\n",
        "\n",
        "print(\"before training:\", loss_func(model(xb), yb), sep=\"\\n\\t\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n - 1) // bs + 1):\n",
        "    start_idx = i * bs\n",
        "    end_idx = start_idx + bs\n",
        "\n",
        "    xb = x_train[start_idx : end_idx]\n",
        "    yb = y_train[start_idx : end_idx]\n",
        "\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "print(\"after training: \", loss_func(model(xb), yb), sep=\"\\n\\t\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTh_S4V1DD4-",
        "outputId": "40496831-3edb-4b61-ab50-5a337930efc0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training:\n",
            "\ttensor(2.3053, grad_fn=<NllLossBackward0>)\n",
            "after training: \n",
            "\ttensor(0.8496, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Organizing data with torch.utils.data.Dataset"
      ],
      "metadata": {
        "id": "q6taTmWNBByt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're also manually handling the data.\n",
        "First, we're independently and manually aligning\n",
        "the inputs, `x_train`, and the outputs, `y_train`.\n",
        "\n",
        "Aligned data is important in ML.\n",
        "We want a way to combine multiple data sources together\n",
        "and index into them simultaneously.\n",
        "\n",
        "That's done with `torch.utils.data.Dataset`.\n",
        "Just inherit from it and implement two methods to support indexing:\n",
        "`__getitem__` and `__len__`."
      ],
      "metadata": {
        "id": "NTD4xJ5zBMYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from text_recognizer.data.util import BaseDataset\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)"
      ],
      "metadata": {
        "id": "rAZtE8WfFksZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below will pull up the documentation for this class,\n",
        "which effectively just indexes into the two `Tensor`s simultaneously.\n",
        "\n",
        "It can also apply transformations to the inputs and targets.\n",
        "We'll see that later."
      ],
      "metadata": {
        "id": "GowtHa7RGC2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BaseDataset??"
      ],
      "metadata": {
        "id": "WriGMxxoGMAs"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "opt = config_optimizer(model)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n - 1) // bs + 1):\n",
        "    xb, yb = train_ds[ i * bs : i * bs + bs]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_H5eDNkGQRG",
        "outputId": "11927fc9-3582-451a-ce33-bfa4fc8d501f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8343, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Batching up data with torch.utils.data.DataLoader"
      ],
      "metadata": {
        "id": "Mo8WSeSQBMjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're also still manually building our batches.\n",
        "\n",
        "Making batches out of datasets is a core component of contemporary deep learning training workflows,\n",
        "so unsurprisingly PyTorch offers a tool for it: the `DataLoader`.\n",
        "\n",
        "We just need to hand our `Dataset` to the `DataLoader`\n",
        "and choose a `batch_size`.\n",
        "\n",
        "We can tune that parameter and other `DataLoader` arguments,\n",
        "like `num_workers` and `pin_memory`,\n",
        "to improve the performance of our training loop.\n",
        "For more on the impact of `DataLoader` parameters on the behavior of PyTorch code, see\n",
        "[this blog post and Colab](https://wandb.ai/wandb/trace/reports/A-Public-Dissection-of-a-PyTorch-Training-Step--Vmlldzo5MDE3NjU)."
      ],
      "metadata": {
        "id": "04iGWRO3BTpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds,  batch_size = bs)"
      ],
      "metadata": {
        "id": "oqGfJaCUOm0c"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self: nn.Module, train_dataloader: DataLoader):\n",
        "  opt = config_optimizer(self)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for xb, yb in train_dataloader:\n",
        "      pred = self(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "MNISTLogistic.fit = fit"
      ],
      "metadata": {
        "id": "qe0hyad_O-Yy"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "\n",
        "model.fit(train_dataloader)\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S5WbpDuPeVq",
        "outputId": "c02450ca-a5ee-46c8-f037-e9dfa6b0516f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8522, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare this training loop with our first training loop - much cleaner and much more powerfull!"
      ],
      "metadata": {
        "id": "huwHwLA7PnxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Swapping in another model"
      ],
      "metadata": {
        "id": "X7FsU1TeBTyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see that our new `.fit` is more powerful,\n",
        "let's use it with a different model.\n",
        "\n",
        "Specifically, let's draw in the `MLP`,\n",
        "or \"multi-layer perceptron\" model\n",
        "from the `text_recognizer` library\n",
        "in our codebase."
      ],
      "metadata": {
        "id": "BhWb-QxBBZOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from text_recognizer.models.mlp import MLP\n",
        "\n",
        "\n",
        "MLP.fit = fit  # attach our fitting loop"
      ],
      "metadata": {
        "id": "PoKELbcL1A88"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you look in the `.forward` method of the `MLP`,\n",
        "you'll see that it uses\n",
        "some modules and functions we haven't seen, like\n",
        "[`nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
        "and [`F.relu`](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html),\n",
        "but otherwise fits the interface of our training loop:\n",
        "the `MLP` is callable and it takes an `x` and returns a guess for the `y` labels."
      ],
      "metadata": {
        "id": "HvMYPFuj1FzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.forward??"
      ],
      "metadata": {
        "id": "sXW6o9Qg1RB_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we look at the constructor, `__init__`,\n",
        "we see that the `nn.Module`s (`fc` and `dropout`)\n",
        "are initialized and attached as attributes."
      ],
      "metadata": {
        "id": "CxnBxwjl1WaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.__init__??"
      ],
      "metadata": {
        "id": "L9hZ4VTM1c0C"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also see that we are required to provide a `data_config`\n",
        "dictionary and can optionally configure the module with `args`.\n",
        "\n",
        "For now, we'll only do the bare minimum and specify\n",
        "the contents of the `data_config`:\n",
        "the `input_dims` for `x` and the `mapping`\n",
        "from class index in `y` to class label,\n",
        "which we can see are used in the `__init__` method."
      ],
      "metadata": {
        "id": "Tn1N7m8R1c4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits_to_9 = list(range(10))\n",
        "data_config = {\"input_dims\": (784,), \"mapping\": {digit: str(digit) for digit in digits_to_9}}\n",
        "data_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8kWGcmO1c9b",
        "outputId": "8c6f3ba5-b6b5-48d1-9981-c498359a628f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_dims': (784,),\n",
              " 'mapping': {0: '0',\n",
              "  1: '1',\n",
              "  2: '2',\n",
              "  3: '3',\n",
              "  4: '4',\n",
              "  5: '5',\n",
              "  6: '6',\n",
              "  7: '7',\n",
              "  8: '8',\n",
              "  9: '9'}}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(data_config)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beVZ2oJm1dDS",
        "outputId": "e619e5db-703c-415c-abb6-59a3ca7f7da7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting MLP is a bit larger than our `MNISTLogistic` model"
      ],
      "metadata": {
        "id": "voKaWJ5N2lwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PumQlHoh2wq-",
        "outputId": "9e1c155a-0fc9-425c-f7b0-f641d7e916ce"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0164,  0.0040,  0.0250,  ...,  0.0173, -0.0052, -0.0270],\n",
              "        [ 0.0108, -0.0139, -0.0141,  ..., -0.0291, -0.0062,  0.0229],\n",
              "        [ 0.0277, -0.0050, -0.0258,  ...,  0.0220,  0.0345, -0.0262],\n",
              "        ...,\n",
              "        [-0.0004, -0.0104, -0.0324,  ..., -0.0116, -0.0024, -0.0167],\n",
              "        [ 0.0071, -0.0309, -0.0323,  ..., -0.0029, -0.0274,  0.0198],\n",
              "        [-0.0259, -0.0194,  0.0125,  ...,  0.0082,  0.0080, -0.0015]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But that doesn't matter for our fitting loop, which happily optimizes this model on batches from the `train_dataloader`, though it takes a bit longer."
      ],
      "metadata": {
        "id": "ZW7nI_M-24PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print(\"before training:\", loss_func(model(xb), yb))\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = bs)\n",
        "fit(model, train_dataloader)\n",
        "\n",
        "print(\"after training:\", loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Peuoi-S33LeZ",
        "outputId": "f25d49c1-0f0a-4f25-81a0-5a9850e15896"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training: tensor(0.2491, grad_fn=<NllLossBackward0>)\n",
            "after training: tensor(0.1292, grad_fn=<NllLossBackward0>)\n",
            "CPU times: user 23.6 s, sys: 66.4 ms, total: 23.7 s\n",
            "Wall time: 28.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extra goodies: data organization, validation, and acceleration"
      ],
      "metadata": {
        "id": "mYFqq2fQ3-Jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we've got a DNN fitting loop that's welcome in polite company,\n",
        "we need three more features:\n",
        "organized data loading code, validation, and GPU acceleration."
      ],
      "metadata": {
        "id": "jsNMVgLO4LNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Making the GPU go brrr"
      ],
      "metadata": {
        "id": "tE3WzasU5hSF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8-nkci6c5hYG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-vGZTpEMFzTU",
        "-wYc7ipEGHWk",
        "5kg1nFaII5Ma"
      ],
      "authorship_tag": "ABX9TyM18aXT05GTWpRY6MzTH4cV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}